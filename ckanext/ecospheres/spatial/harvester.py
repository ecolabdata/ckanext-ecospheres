# encoding: utf-8

import ckan.plugins as plugins
import ckan.plugins.toolkit as toolkit
from ckan.model.package import Package
from ckan.lib.helpers import json
from lxml import etree

from ckanext.spatial.interfaces import ISpatialHarvester
from ckanext.harvest.harvesters.base import HarvesterBase


class FrSpatialHarvester(plugins.SingletonPlugin):
    '''Customization of spatial metadata harvest.
    
    See :py:class:`ckanext.spatial.harvesters.base.SpatialHarvester`.
    
    '''

    plugins.implements(ISpatialHarvester, inherit=True)
    
    def get_package_dict(self, context, data_dict):
        '''Add some usefull informations to package metadata dictionnary.
        
        :param context: contains a reference to the model, eg to
            perform DB queries, and the user name used for
            authorization.
        :type context: dict
        :param data_dict: available data. Contains four keys:
            * `package_dict`
               The default package_dict generated by the harvester. Modify this
               or create a brand new one.
            * `iso_values`
               The parsed ISO XML document values. These contain more fields
               that are not added by default to the ``package_dict``.
            * `xml_tree`
               The full XML etree object. If some values not present in
               ``iso_values`` are needed, these can be extracted via xpath.
            * `harvest_object`
               A ``HarvestObject`` domain object which contains a reference
               to the original metadata document (``harvest_object.content``)
               and the harvest source (``harvest_object.source``).
        :type data_dict: dict
        
        :returns: a dataset dict ready to be used by ``package_create`` or
                  ``package_update``
        :rtype: dict
        
        See :py:func:`ckanext.spatial.harvesters.base.SpatialHarvester.get_package_dict`
        and :py:func:`ckanext.spatial.interface.ISpatialHarvester.get_package_dict`.
        
        '''
        package_dict = data_dict['package_dict']
        iso_values = data_dict['iso_values'] 
        xml_tree = data_dict['xml_tree']
        
        # adding some useful categories from iso_values
        for key in ('lineage', 'topic-category', 'equivalent-scale', 'metadata-point-of-contact', 'use-constraints', 'aggregation-info', 'temporal-extent-begin', 'temporal-extent-end', 'bbox'):
            value = iso_values[key]
            if value and isinstance(value, (list, dict)):
                package_dict[key] = json.dumps(value)
            elif value:
                package_dict[key] = value
        
        # more straight-forward serialization for dates
        value = {}
        for date_object in iso_values['dataset-reference-date']:
            value.update({date_object['type']: date_object['value']})

        if value:
            package_dict['dataset-reference-date'] = json.dumps(value)

        # get other fields from extras
        extras_to_keep = ['guid', 'metadata-date', 'resource-type', 'licence', 'spatial', 'spatial-reference-system', 'metadata-language', 'coupled-resource', 'access_constraints', 'graphic-preview-file']
        for extra in package_dict['extras'].copy():
            field = extra['key']
            if field not in extras_to_keep :
                package_dict['extras'].remove(extra)
            else:
                package_dict[field] = extra['value']
                package_dict['extras'].remove(extra)
        
        # package name should always be its guid, for easier
        # handling of packages relationships and duplicate removal
        package_dict['name'] = package_dict['guid']


        ### LXML parsing ###
        namespaces = {
           "gts": "http://www.isotc211.org/2005/gts",
           "gml": "http://www.opengis.net/gml",
           "gml32": "http://www.opengis.net/gml/3.2",
           "gmx": "http://www.isotc211.org/2005/gmx",
           "gsr": "http://www.isotc211.org/2005/gsr",
           "gss": "http://www.isotc211.org/2005/gss",
           "gco": "http://www.isotc211.org/2005/gco",
           "gmd": "http://www.isotc211.org/2005/gmd",
           "srv": "http://www.isotc211.org/2005/srv",
           "xlink": "http://www.w3.org/1999/xlink",
           "xsi": "http://www.w3.org/2001/XMLSchema-instance",
        }

        # Licence parsing
        licence_parsed = []
        for licence in xml_tree.findall("gmd:identificationInfo/gmd:MD_DataIdentification/gmd:resourceConstraints/gmd:MD_LegalConstraints/gmd:useLimitation/gco:CharacterString",\
                                         namespaces):
            licence_parsed.append(etree.tostring(licence, method='text', encoding=str))
        if package_dict['licence'] == '[]':
            package_dict['licence'] = json.dumps(licence_parsed)
        
        licence_list = json.loads(package_dict['licence'])
        if licence_list:
            license_map = {
                ('etalab', 'licence'): 'etalab-2.0',
                ('licence ouverte',): 'etalab-2.0',
                ('odbl',): 'ODbL-1.0',
                ('open database license',): 'ODbL-1.0'
                }
            for licence in licence_list:
                package_license = None                
                for keywords, license_id in license_map.items() :
                    if all(w in licence.lower() for w in keywords):
                        package_license = license_id
                        break
                if package_license:
                    package_dict['license_id'] = package_license
                    break

        # Aggregate parsing
        aggregate_parsed = []
        for agg in xml_tree.findall("gmd:identificationInfo/gmd:MD_DataIdentification/gmd:aggregationInfo/gmd:MD_AggregateInformation/*/gmd:MD_Identifier/gmd:code/gco:CharacterString", namespaces):
            aggregate_parsed.append(etree.tostring(agg, method='text', encoding=str))

        package_dict['aggregate-dataset-identifier'] = json.dumps(aggregate_parsed)

        relationships_as_subject = []
        for rel_guid in aggregate_parsed:
            if rel_guid:
                rel_package = Package.get(rel_guid)
                if rel_package:
                    relationships_as_subject.append(
                        { 'object': rel_package.id, 'type': 'parent_of' }
                        )
                        # TODO: type of relationship should be infered
                        # from rel.get('association-type')
        # package_dict['relationships_as_subject'] = relationships_as_subject # fait planter le moissonnage pour l'instant...

        # print(package_dict)
        # print(iso_values)

        # more accommodating resource format identification
        # and droping every 'Unnamed resource'
        format_map = {
            ('wfs', 'wms'): 'WxS',
            ('wxs',): 'WxS',
            ('wfs',): 'WFS',
            ('wms',): 'WMS',
            ('atom',): 'ZIP',
            ('html',): 'HTML',
            ('xml',): 'XML'
            }
        format_map_url = {
            ('mapservwfs?',): 'WFS',
            ('mapserv?',): 'WMS',
            ('atomdataset',): 'ZIP',
            ('atomarchive',): 'ZIP',
            }
        for resource in package_dict['resources'].copy():
            if resource['name'] == toolkit._('Unnamed resource'):
                package_dict['resources'].remove(resource)
                continue
            if not resource['format']:
                for keywords, format_name in format_map.items() :
                    if all(w in resource['name'].lower() for w in keywords):
                        resource['format'] = format_name
                        break
            if not resource['format']:
                for keywords, format_name in format_map_url.items() :
                    if all(w in resource['url'].lower() for w in keywords):
                        resource['format'] = format_name
                        break
        # if len(aggregate_parsed)>0:
        print("package_dict: ",package_dict)
        return package_dict
        
